import os
import pathlib

from prepare_features import (reproject_and_resample_complex, create_patches, stack_features, to_npy, create_dataset_split, 
rasterize_grounding_lines, get_global_range, scale_features, random_flip)
import geopandas as gpd
import rasterio as rio

from tqdm import tqdm

cwd = pathlib.Path(os.getcwd())

configfile: cwd.parent / 'config.yaml'

for key, value in config['Directories'].items():
    if key == 'work_dir':
        continue
    else:
        config['Directories'][key] = config['Directories']['work_dir'] + '/' + value

manual_grounding_lines = gpd.read_file(config['Directories']['geom_dir'])
interferograms = [interferogram.name.removesuffix('.tif') for interferogram in pathlib.Path(config['Directories']['full_res_dinsar']).glob('*.tif')]

# Create directories for GL rasters and downsampled DInSAR phases
pathlib.Path(config['Directories']['labels_reference']).mkdir(parents = True, exist_ok = True)
pathlib.Path(config['Directories']['downsampled_dinsar']).mkdir(parents = True, exist_ok = True)

features = ['Real', 'Imaginary', 'Pseudocoherence', 'Phase', 'DEM', 
            'Ice velocity easting', 'Ice velocity northing', 'Differential tide', 'Air pressure']

rule all:
    input:
        config['Directories']['features_stack_npz'] + '/OK.all' 

rule downsample:
    input:
        config['Directories']['full_res_dinsar'] + "/{raster}.tif"
    output:
        config['Directories']['downsampled_dinsar'] + "/{raster}.tif"
    run:
        print(f'Downsampling full resolution interferograms...')
        reproject_and_resample_complex(raster = pathlib.Path(input[0]), writedir = pathlib.Path(output[0]).parent, 
                                       dst_crs = 'EPSG:3031', pixel_size = tuple(config['Data']['pixel_size']))

rule rasterize_manual_GL:
    input:
        config['Directories']['downsampled_dinsar'] + "/{raster}.tif"
    output:
        config['Directories']['labels_reference'] + "/{raster}.tif"
    run:
        print(f'Rasterizing manual GL delineations...')
        interferogram = pathlib.Path(input[0])
        rasterize_grounding_lines(dd = interferogram,  
                                gl_df = manual_grounding_lines.loc[manual_grounding_lines.UUID == interferogram.name.removesuffix('.tif')], # UUID is an attribute which refers to the name of the interferogram .tif file.
                                res = config['Data']['pixel_size'][0], 
                                savedir = pathlib.Path(output[0]).parent)

checkpoint create_tiles:
    input:
        interferograms = expand(config['Directories']['downsampled_dinsar'] + '/{raster}.tif', raster = interferograms),
        labels = expand(config['Directories']['labels_reference'] + '/{raster}.tif', raster = interferograms)
    output:
        directory(config['Directories']['features_stack_tif']),
        directory(config['Directories']['labels_tif'])
    run:
        print(f'Creating DInSAR phase tiles...')
        features_path = pathlib.Path(config['Directories']['features_stack_tif'])
        labels_path = pathlib.Path(config['Directories']['labels_tif'])
        features_path.mkdir(parents = True, exist_ok = True)
        labels_path.mkdir(parents = True, exist_ok = True)

        for interferogram, labels in tqdm(zip(input.interferograms, input.labels)):
            create_patches(raster = pathlib.Path(interferogram), overlap = config['Data']['overlap'], savepatches = features_path, 
                            patch_size = config['Data']['tile_dimensions'])
            create_patches(raster = pathlib.Path(labels), overlap = config['Data']['overlap'], savepatches = labels_path, 
                            patch_size = config['Data']['tile_dimensions'])

rule prepare_feature_stacks:
    input:
        config['Directories']['features_stack_tif'] + '/{tile}.tif',
        config['Directories']['labels_tif'] + '/{tile}.tif'
    output:
        config['Directories']['features_stack_npz'] + '/{tile}.npz',
        config['Directories']['labels_npz'] + '/{tile}.npz'
    run:
        print(f'Preparing feature stacks...')
        features_tif = pathlib.Path(input[0])
        stack_features(raster = features_tif, gl = manual_grounding_lines, dem_raster = pathlib.Path(config['Directories']['dem']), 
                        vel_raster = pathlib.Path(config['Directories']['velocity']), cats = pathlib.Path(config['Directories']['cats']), 
                        ap_model = pathlib.Path(config['Directories']['air_pressure']))
        
        with rio.open(features_tif) as tif:
            features = tif.read()
            to_npy(arr = features, name = features_tif.name.removesuffix('.tif'), 
                   savedir = pathlib.Path(config['Directories']['features_stack_npz']), 
                   dest_dim = config['Data']['tile_dimensions'])
        
        with rio.open(pathlib.Path(input[1])) as tif:
            labels = tif.read()
            to_npy(arr = labels, name = features_tif.name.removesuffix('.tif'), 
                  savedir = pathlib.Path(config['Directories']['labels_npz']), 
                  dest_dim = config['Data']['tile_dimensions'])

def aggregate_tiles(wildcards):
    feature_tiles_dir = checkpoints.create_tiles.get(**wildcards).output[0]
    feature_tiles_dir = pathlib.Path(feature_tiles_dir)

    return expand(config['Directories']['features_stack_npz'] + '/{tile}.npz', tile = glob_wildcards(feature_tiles_dir / '{tile}.tif').tile)  

rule split_dataset:
    input:
        aggregate_tiles
    output:
        config['Directories']['split'],
        config['Directories']['features_stack_npz'] + '/OK.created_dataset_split',
        config['Directories']['features_stack_npz'] / 'features_in_stack.txt'
    run:
        print(f'Split dataset into training, validation and test sets...')

        tif_tiles = list((config['Directories']['features_stack_tif']).glob('*.tif'))

        with rio.open(tif_tiles[0]) as tif:
            features_in_stack = tif.descriptions

        with open(output[1], 'w') as out:
            for description in features_in_stack:
                band = [feature for feature in features if feature in description]
                if len(band) == 1:
                    out.write(band[0] + '\n')

        create_dataset_split(tiles_npz = pathlib.Path(config['Directories']['features_stack_npz']), 
                            labels_npz = pathlib.Path(config['Directories']['labels_npz']),
                            grounding_lines = manual_grounding_lines, split_file = pathlib.Path(config['Directories']['split']))
        
        with open(output[1], 'w') as out:
            out.write('Ok')

rule augment_train_tiles:
    input:
        config['Directories']['features_stack_npz'] + '/OK.created_dataset_split',
        config['Directories']['split']
    output:
        config['Directories']['features_stack_npz'] + '/OK.augmented_train_tiles'
    run:
        print(f'Augmenting training tiles...')
        with open(config['Directories']['split']) as split_info:
            split = split_info.readlines()
            split = [elem.strip() for elem in split]
        
        train_tiles = split[split.index('train_valids') + 1:split.index('train_empties')] + split[split.index('train_empties') + 1:split.index('validation_valids')]
        tiles_dir = pathlib.Path(config['Directories']['features_stack_npz'])
        labels_dir = pathlib.Path(config['Directories']['labels_npz'])
        for tile in tqdm(train_tiles):
            random_flip(tile = tiles_dir / tile, label = labels_dir / tile, savetile = tiles_dir, savelabel = labels_dir)
        
        with open(output[0], 'w') as out:
            out.write('Ok')
    
rule scale_features:
    input:
        config['Directories']['features_stack_npz'] + '/OK.augmented_train_tiles',
        config['Directories']['split'],
        config['Directories']['features_stack_npz'] / 'features_in_stack.txt'
    output:
        config['Directories']['features_stack_npz'] + '/OK.scaled_features',
        config['Directories']['features_stack_npz'] + '/OK.all'
    run:
        print(f'Applying global scaling to each feature...')
        tiles_dir = pathlib.Path(config['Directories']['features_stack_npz'])
        with open(input[1]) as split_info:
            split = split_info.readlines()
            split = [elem.strip() for elem in split if elem != '\n']

        train_tiles = split[split.index('train_valids')+1:split.index('train_empties')] + split[split.index('train_empties')+1:split.index('validation_valids')]
        validation_tiles = split[split.index('validation_valids')+1:split.index('validation_empties')] + split[split.index('validation_empties')+1:split.index('test_valids')]
        test_tiles = split[split.index('test_valids')+1:split.index('test_empties')] + split[split.index('test_empties')+1:]

        tiles = train_tiles + validation_tiles + test_tiles
        tiles = [tiles_dir / tile for tile in tiles]

        bands = []
        ignore_values = []
        with open(input[0]) as f:
            features_in_stack = f.readlines()
            features_in_stack = [feature.strip() for feature in features_in_stack]
            if 'DEM' in features_in_stack:
                bands.append(4)
                ignore_values.append(-32767.0)
            if 'Ice velocity easting' in features_in_stack:
                bands.append(5)
                ignore_values.append(3.4e38)
            if 'Ice velocity northing' in features_in_stack:
                bands.append(6)
                ignore_values.append(3.4e38)
            if 'Differential tide' in features_in_stack:
                bands.append(7)
                ignore_values.append(np.nan)

        print(f'Bands: {bands}, ignore_values: {ignore_values}')

        global_range = get_global_range(tiles = tiles, bands = bands, ignore_values = [None, None, None, None])
        
        print(f'Global range: {global_range}')
        for tile in tqdm(tiles_dir.glob('*.npz')):
            scale_features(tile = tile, savedir = tiles_dir, global_max_mins = global_range, bands = bands)
        
        with open(output[0], 'w') as out:
            out.write('Ok')
        
        with open(output[1], 'w') as out:
            out.write('Ok')